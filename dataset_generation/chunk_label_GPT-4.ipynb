{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"\"\n",
    "client = AsyncOpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "async def prompt_gpt(prompt):\n",
    "  return await client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4-turbo-preview\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/174\n",
      "1/174\n",
      "2/174\n",
      "3/174\n",
      "4/174\n",
      "5/174\n",
      "6/174\n",
      "7/174\n",
      "8/174\n",
      "9/174\n",
      "10/174\n",
      "11/174\n",
      "12/174\n",
      "13/174\n",
      "14/174\n",
      "15/174\n",
      "16/174\n",
      "17/174\n",
      "18/174\n",
      "19/174\n",
      "20/174\n",
      "21/174\n",
      "22/174\n",
      "23/174\n",
      "24/174\n",
      "25/174\n",
      "26/174\n",
      "27/174\n",
      "28/174\n",
      "29/174\n",
      "30/174\n",
      "31/174\n",
      "32/174\n",
      "33/174\n",
      "34/174\n",
      "35/174\n",
      "36/174\n",
      "37/174\n",
      "38/174\n",
      "39/174\n",
      "40/174\n",
      "41/174\n",
      "42/174\n",
      "43/174\n",
      "44/174\n",
      "45/174\n",
      "46/174\n",
      "47/174\n",
      "48/174\n",
      "49/174\n",
      "50/174\n",
      "51/174\n",
      "52/174\n",
      "53/174\n",
      "54/174\n",
      "55/174\n",
      "56/174\n",
      "57/174\n",
      "58/174\n",
      "59/174\n",
      "60/174\n",
      "61/174\n",
      "62/174\n",
      "63/174\n",
      "64/174\n",
      "65/174\n",
      "66/174\n",
      "67/174\n",
      "68/174\n",
      "69/174\n",
      "70/174\n",
      "71/174\n",
      "72/174\n",
      "73/174\n",
      "74/174\n",
      "75/174\n",
      "76/174\n",
      "77/174\n",
      "78/174\n",
      "79/174\n",
      "80/174\n",
      "81/174\n",
      "82/174\n",
      "83/174\n",
      "84/174\n",
      "85/174\n",
      "86/174\n",
      "87/174\n",
      "88/174\n",
      "89/174\n",
      "90/174\n",
      "91/174\n",
      "92/174\n",
      "93/174\n",
      "94/174\n",
      "95/174\n",
      "96/174\n",
      "97/174\n",
      "98/174\n",
      "99/174\n",
      "100/174\n",
      "101/174\n",
      "102/174\n",
      "103/174\n",
      "104/174\n",
      "105/174\n",
      "106/174\n",
      "107/174\n",
      "108/174\n",
      "109/174\n",
      "110/174\n",
      "111/174\n",
      "112/174\n",
      "113/174\n",
      "114/174\n",
      "115/174\n",
      "116/174\n",
      "117/174\n",
      "118/174\n",
      "119/174\n",
      "120/174\n",
      "121/174\n",
      "122/174\n",
      "123/174\n",
      "124/174\n",
      "125/174\n",
      "126/174\n",
      "127/174\n",
      "128/174\n",
      "129/174\n",
      "130/174\n",
      "131/174\n",
      "132/174\n",
      "133/174\n",
      "134/174\n",
      "135/174\n",
      "136/174\n",
      "137/174\n",
      "138/174\n",
      "139/174\n",
      "140/174\n",
      "141/174\n",
      "142/174\n",
      "143/174\n",
      "144/174\n",
      "145/174\n",
      "146/174\n",
      "147/174\n",
      "148/174\n",
      "149/174\n",
      "150/174\n",
      "151/174\n",
      "152/174\n",
      "153/174\n",
      "154/174\n",
      "155/174\n",
      "156/174\n",
      "157/174\n",
      "158/174\n",
      "159/174\n",
      "160/174\n",
      "161/174\n",
      "162/174\n",
      "163/174\n",
      "164/174\n",
      "165/174\n",
      "166/174\n",
      "167/174\n",
      "168/174\n",
      "169/174\n",
      "170/174\n",
      "171/174\n",
      "172/174\n",
      "173/174\n"
     ]
    }
   ],
   "source": [
    "genre = 'code'\n",
    "from_scratch = True\n",
    "\n",
    "texts=np.load('Dataset/Approved_data/approved_texts_'+genre+'.npy')\n",
    "\n",
    "if from_scratch:\n",
    "    labeled_texts = []\n",
    "else:\n",
    "    labeled_texts = np.load('Dataset/Approved_data/labeled_text_chunks_'+genre+'.npy')\n",
    "    \n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    if i>=len(labeled_texts):\n",
    "        print(str(i)+'/'+str(len(texts)))\n",
    "        text_sample = texts[i]\n",
    "        label = await prompt_gpt('Please return a json list that sections the text below and labels it according to one of these categories:\\n\\n instructional, narrative, explanatory, speech, code, other. \\n\\n Please escape characters such as \"\\n\". \\n\\n Here is how you should format the output: [\\n {\"text\": ..., \"category\": ...}, \\n {\"text\": ..., \"category\": ...}, \\n ... \\n ] \\n\\n'+text_sample)\n",
    "        label=label.choices[0].message.content\n",
    "        labeled_texts=np.append(labeled_texts,label)\n",
    "        np.save('Dataset/Approved_data/labeled_text_chunks_'+genre,labeled_texts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
